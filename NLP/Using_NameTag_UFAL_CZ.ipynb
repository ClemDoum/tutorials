{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "import requests\n",
    "from xml.etree import ElementTree\n",
    "import time\n",
    "\n",
    "def tokenize_sentences(sentences, use_ufal = False):\n",
    "    tokenized_sentences = []\n",
    "    \n",
    "    if not use_ufal:\n",
    "        for index, msg in enumerate(sentences):\n",
    "            sentences = []\n",
    "            for sent in sent_tokenize(msg, language=\"czech\"):\n",
    "                sentence = []\n",
    "                for token in word_tokenize(sent):\n",
    "                    sentence.append(token)\n",
    "                sentences.append(sentence)\n",
    "            tokenized_sentences.append((msg, sentences))\n",
    "    else: # -----------------------------------------------------------------\n",
    "        for index, msg in enumerate(sentences):\n",
    "            msg = msg.strip()\n",
    "\n",
    "            try:\n",
    "                files = {\n",
    "                    ('data', msg),\n",
    "                    ('output', 'xml'),\n",
    "                    ('model', 'czech-cnec2.0-140304')\n",
    "                }\n",
    "\n",
    "                response_pos = requests.get('http://lindat.mff.cuni.cz/services/nametag/api/recognize', params=files)\n",
    "                root = ElementTree.fromstring(\"<root>\" + response_pos.json()[\"result\"] + \"</root>\")\n",
    "\n",
    "                sentences = []\n",
    "\n",
    "                for sent in root.iter(\"sentence\"):\n",
    "                    sentence = []\n",
    "                    bool_ne = False\n",
    "                    for token in sent.iter():\n",
    "                        if token.tag == \"ne\":\n",
    "                            if token.attrib.get(\"type\").startswith(\"a\"):\n",
    "                                sentence.append(\"adresa\")\n",
    "                            elif token.attrib.get(\"type\").startswith(\"g\"):\n",
    "                                sentence.append(\"místo\")\n",
    "                            elif token.attrib.get(\"type\").startswith(\"i\"):\n",
    "                                sentence.append(\"instituce\")\n",
    "                            elif token.attrib.get(\"type\").startswith(\"m\"):\n",
    "                                sentence.append(\"soubor\")\n",
    "                            elif token.attrib.get(\"type\").startswith(\"n\"):\n",
    "                                sentence.append(\"číslo\")\n",
    "                            elif token.attrib.get(\"type\").startswith(\"o\"):\n",
    "                                sentence.append(\"produkt\")\n",
    "                            elif token.attrib.get(\"type\").startswith(\"p\"):\n",
    "                                sentence.append(\"jméno\")\n",
    "                            elif token.attrib.get(\"type\").startswith(\"t\"):\n",
    "                                sentence.append(\"čas\")\n",
    "                            bool_ne = True\n",
    "\n",
    "                        elif token.tag == \"token\" and bool_ne == False:\n",
    "                            sentence.append(token.text)\n",
    "                        elif bool_ne:\n",
    "                            bool_ne = False\n",
    "\n",
    "                    sentences.append(sentence)\n",
    "\n",
    "            except Exception as e:\n",
    "                print (\"Error with \" + msg)\n",
    "                print (str(e))\n",
    "\n",
    "            tokenized_sentences.append((msg, sentences))\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoj|,|jak|se|mas|?\n",
      "Když|napíšu|jméno|tak|to|jde|,|ale|pokud|jenom|jakub|tak|to|nic|nenajde|.\n",
      "No|,|prostě|to|neni|dokonalé\n"
     ]
    }
   ],
   "source": [
    "for orig, sentences in tokenize_sentences([\"Ahoj, jak se mas? Když napíšu Jakub tak to jde, ale pokud jenom jakub tak to nic nenajde. No, prostě to neni dokonalé\"], use_ufal=True):\n",
    "    for sent in sentences:\n",
    "        print (\"|\".join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
